---
layout: post
title: A General Framework for Estimating Graphlet Statistics via Random Walk
subtitle : X. Chen et al. / 2016 / VLDB
tags: [graphlets, algorithm, random walk, pattern mining]
author: Hyunju Kim
comments : False
---


[abstract]

- propose a framewalk to estimate graphlet statistics of “any size”
- analytic bound of the sample size (Chernoff-Hoeffding) to guarantee convergence

[1. introduction]

- estimating graphlets is more complicated than estimating local structures (e.g. degree distribution)

[1.1 Related Works and Existing Problems]

1. memory-based graphs : wedge sampling
    - need access to the whole graph
2. streaming graphs
    - access each edge at least once
3. restricted accessed graphs : SRW, **PSRW**, MSS
    - random walk based methods

[1.2 Our contributions]

1. novel framework
    - no assumption on the graph structures
    - propose a new and general frameworks which subsumes PSRW
2. efficient optimization techniques
    - corresponding state sampling (CSS)
    - non-backtracking random walk

[2.1 Notations and Definitions]

- $G^{(d)}=(H^{(d)}, R^{(d)})$: d-node subgraph relationship graph
- $H^{(d)}$: the set of all d-node connected induced subgraphs of G
- For $s_i, s_j\in H^{(d)}$, if they share d-1 common nodes in G, there is an edge. Denote the set of these edges as $R^{(d)}$.
- For d=1, define $G^{(1)}=G$ (and the same for H, R)

⇒ constructing $G^{(d)}$ requires compuational cost. no need to construct it using random-walk technique

⇒ The number of distinct graphlets grows exponentially with the numbeer of vertices in the graphlets

⇒ **problem definition**: estimate “concentration of graphlets”

[2.2 Random walk and Markov Chain]

- A simple random walk (SRW)
    - random walk : a finite and time-reversible Markov chain with state space V
        - $\{X_t\}$: Markov chain representing the visited nodes of the random walk on G
        - P: transition probability defined as $P(i,j)=1/d_i$ if $(i,j)\in E$ and 0 otherwise.
    - unique stationary distribution $\pi$  where $\pi(v)=d_v/2|E|$ ⇒ correct bias
- Strong Law of Large Numbers (SLLN)

![Untitled]({{ site.baseurl }}/assets/img/RW/Untitled.png)

![Untitled]({{ site.baseurl }}/assets/img/RW/Untitled%201.png)

⇒ By SLLN, $\hat{\mu}_n$ converges to $\mu$ .

- Mixing time : the numbeer of steps it takes for a random walk to approach its stationary distribution
    
    ![Untitled]({{ site.baseurl }}/assets/img/RW/Untitled%202.png)
    

[3.1 Basic Idea]

- d는 hyperparameter로, $G^{(d)}$와 $l=k-d+1$ consecutive steps를 결정
- 각 $X_i (i\geq l)$ 스텝마다 $l-1$ 개의 전 스텝을 기억

[3.2 Expanded Markov Chain]

- Each $l$ consecutive steps are considered as a state $X^{(l)}=(X_1, \cdots, X_l)$ of the expanded Markov chain
- state space $M^{(l)} = \{(X_1, \cdots, X_l): X_i\in N, 1\leq i\leq l \text{ s.t. } (X_i, X_{i+1})\in R^{(d)} \;\forall 1\leq i\leq l-1\}$
- bias occurs
    1. states in the expanded Markov chain do not have eqal stational probabilities
    2. a graphlet samples corresponds to several states

![Untitled]({{ site.baseurl }}/assets/img/RW/Untitled%203.png)

- state corresponding coefficient $\alpha_i^k = |C(s)|$ where $C(s)=\{X^{(l)}|s(X^{(l)})=s, X^{(l)}\in M^{(l)}\}$.
- if states in $M^{(l)}$ are uniformly sampled, then the probability of getting a subgraph isomorphic to $g_i^k$ is $\alpha_i^kC_i^k/|M^{(l)}|$.
- $\alpha_i^k$= twice the number of Hamiltonian paths

[3.3 Unbiased Estimator]

- $h_i^k(X^{(l)})=1\{s(X^{(l)})= g_i^k\}$.
- $\sum_{X^{(l)}\in M^{(l)}} h_i^k(X^{(l)})=\alpha_i^kC_i^k$.

![Untitled]({{ site.baseurl }}/assets/img/RW/Untitled%204.png)

![Untitled]({{ site.baseurl }}/assets/img/RW/Untitled%205.png)

![Untitled]({{ site.baseurl }}/assets/img/RW/Untitled%206.png)

[4.1 Corresponding State Sampling (CSS)]

![Untitled]({{ site.baseurl }}/assets/img/RW/Untitled%207.png)