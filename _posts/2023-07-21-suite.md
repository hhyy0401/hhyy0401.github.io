---
layout: post
title: NAS-Bench-Suite - NAS Evaluation is (Now) Surprisingly Easy
subtitle : Yash Mehta et al. / 2022 /  ICLR
tags: [NAS, performance prediction]
author: Hyunju Kim
comments : False
---

[Abstract]

- NAS-Bench-201과 같은 벤치마크 데이터셋들이 compuatational overhead를 낮추었다
- 그러나 이러한 벤치마크는 small search space에 제한되어있다
- 소수의 NAS 벤치마크에서 유도된 결론이 다른 벤치마크에도 일반화가 되지 않는다는 사실을 밝혔다
- 통일된 interface인 NAS-Bench-Suite를 소개했다

[1. Introduction]

→ NAS method들은 공정한 비교가 어려움

→ 벤치마크 데이터 생김

→ 초창기 벤치마크는 small serach space나 image classification에 국한됨

→ 벤치마크 데이터셋은 일관성이 떨어짐 (abstractions, capabilities, implementations)

⇒ 유의미한 분석을 제시

- 몇몇 벤치마크에서 잘 작동하더라도 다른 search space에서 잘 작동하지 않을 우려가 있음
- NAS 알고리즘들은 robust default 하이퍼파라미터가 없으며, tuning이 요구됨
- 한 search space에서의 hyperparameter를 다른 search space로 이동할 시, 성능을 매우 악화시킬 수 있음

⇒ NAS-Bench-Suite를 제시 (unified interface)

[2. NAS Benchmarks Overview]

- most search space
    - cell-based (micro) structure: DAG form
    - macro structure: architecture skeletons, arrangement of cells, such as how many times each cell is duplicated

![Untitled](/assets/img/suite/Untitled.png)

[3. NAS Benchmarks Statistics]

- NAS-Bench-Suite: the first large-scale aggregation of statistics computed on NAS Benchmarks
    
    ![Untitled](/assets/img/suite/Untitled%201.png)
    
    - assess the level of locality (similarity of validation accuracy among neighboring architectures)
        
        ⇒ NAS-Bench-201 Imagenet, CIFAR 10 (highest autocorrelation)
        
- diversity
    - DARTS의 std가 NAS-Bench-201보다 낮기 때문에, NAS-Bench-201의 0.1% optimal한 arcitecture을 찾는 것이 더 인상적일 것이다
- locality와 neighborhood size도 NAS 벤치마크의 어려움에 영향을 끼칠 수도 있다

[4. On the Generalizability of NAS Algorithms]

- 5 black-box algorithms
    - iteratively chooses architectures to train
    - uses the final validation accuracies
    - random search, regularized evolution, local search, BANNAS, NPENAS
- 5 performance predictors
    - predict performance of untrained architectures by training model using a set of already evaluated architectures
    - BOHAMIANN, Gaussian process, Random forest, Neural architecture optimziation, XGBoost
- 3 one-shot methods

⇒ assess 3 assumptions (refer to introduction)

[4.1 The Best NAS Methods]

- black-box algorithms
    - no algorithm performs well across al search space
- performance predictor
    - with default parameters: RF
    - with tuned parameters: XGBoost

![Untitled](/assets/img/suite/Untitled%202.png)

![Untitled](/assets/img/suite/Untitled%203.png)

[4.2 Generalizability of Hyperparameters]

![Untitled](/assets/img/suite/Untitled%204.png)

[4.3 One-shot Algorithms]

- DARTS, GDAS, DrNAS
- must be able to represent entire search space → supernetworks

![Untitled](/assets/img/suite/Untitled%205.png)